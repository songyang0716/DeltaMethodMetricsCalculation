{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T00:18:37.221131Z",
     "start_time": "2019-10-08T00:18:35.576978Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T06:03:29.296222Z",
     "start_time": "2019-10-08T06:03:29.292560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of clusters in each cohorts\n",
    "N = 5000\n",
    "\n",
    "# The average number of samples in each cluster follows a poisson distribution with mean lambda\n",
    "mean_samples = 5\n",
    "\n",
    "# Number of simulations\n",
    "n_iterations = 10000\n",
    "\n",
    "# Conversion Rate - Follow a Beta Distribution\n",
    "alpha = 1\n",
    "beta = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T06:03:30.331902Z",
     "start_time": "2019-10-08T06:03:30.329189Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type One Error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under cluster level, randomization unit is same as the analysis unit  (Correct way !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T17:53:50.202018Z",
     "start_time": "2019-10-08T17:53:25.360757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type One Error : 0.0481\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metric in cluster level\n",
    "# 5% significance level\n",
    "false_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha, beta, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha, beta, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    # conversion in each cluster\n",
    "    control_cluster_conversion = control_converted / control_samples_per_cluster\n",
    "    treatment_cluster_conversion = treatment_converted / treatment_samples_per_cluster\n",
    "\n",
    "    # perform t-test\n",
    "    control_mean, var_c = np.mean(control_cluster_conversion),  np.var(\n",
    "        control_cluster_conversion, ddof=1)\n",
    "    treatment_mean, var_t = np.mean(treatment_cluster_conversion), np.var(\n",
    "        treatment_cluster_conversion, ddof=1)\n",
    "    t_score = (treatment_mean - control_mean) / np.sqrt(var_c / N + var_t / N)\n",
    "\n",
    "    if (t_score >= 1.96) or (t_score <= -1.96):\n",
    "        false_positive += 1\n",
    "\n",
    "print(\"Type One Error : {}\".format(false_positive / n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under sample level, analysis unit is more granular than the randomization unit (Wrong way !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:15:33.629637Z",
     "start_time": "2019-10-08T20:14:45.607467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type One Error : 0.1804\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metric in sample level\n",
    "# 5% significance level\n",
    "false_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha, beta, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha, beta, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    # conversion in each cohort\n",
    "    control_cluster_conversion = sum(control_converted) / sum(control_samples_per_cluster)\n",
    "    treatment_cluster_conversion = sum(treatment_converted) / sum(treatment_samples_per_cluster)\n",
    "\n",
    "    # perform two proportion z-test\n",
    "    control_mean, var_c = control_cluster_conversion,  control_cluster_conversion * (1 - control_cluster_conversion)\n",
    "    treatment_mean, var_t = treatment_cluster_conversion, treatment_cluster_conversion * (1 - treatment_cluster_conversion)\n",
    "    z_score = (treatment_mean - control_mean) / np.sqrt(var_c / sum(control_samples_per_cluster) + var_t / sum(treatment_samples_per_cluster))\n",
    "\n",
    "    if (z_score >= 1.96) or (z_score <= -1.96):\n",
    "        false_positive += 1\n",
    "\n",
    "print(\"Type One Error : {}\".format(false_positive / n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T06:15:57.566523Z",
     "start_time": "2019-10-08T06:15:57.563879Z"
    }
   },
   "outputs": [],
   "source": [
    "### Woooo !  False positive is way higher than what we expected ! The reason is \n",
    "### In the above simulation, We draw samples from different clusters \n",
    "### If two samples are coming from the same clusters, they are no longer independent to each other !!!\n",
    "### when x, y are from the same cluster, P(x|y) != p(x)\n",
    "\n",
    "### So the sample mean variance estimation is no longer accurate, which is smaller than what it's suppose to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T16:34:59.253925Z",
     "start_time": "2019-10-08T16:34:59.245338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29979"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(control_samples_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T16:35:13.460298Z",
     "start_time": "2019-10-08T16:35:13.455230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29900"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(treatment_samples_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T17:01:09.214321Z",
     "start_time": "2019-10-08T17:01:09.207062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(control_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T17:01:17.478905Z",
     "start_time": "2019-10-08T17:01:17.474889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(control_samples_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T17:37:41.828766Z",
     "start_time": "2019-10-08T17:37:41.817606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25367757430201143"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(control_cluster_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T17:37:51.560957Z",
     "start_time": "2019-10-08T17:37:51.556473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.245685618729097"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(treatment_cluster_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use delta method to correct for the variance estimation (from the paper https://arxiv.org/pdf/1803.06336.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:11:02.664542Z",
     "start_time": "2019-10-09T00:10:34.998239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type One Error : 0.0497\n"
     ]
    }
   ],
   "source": [
    "false_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha, beta, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha, beta, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    S_mean_control = np.mean(control_converted)\n",
    "    N_mean_control = np.mean(control_samples_per_cluster)\n",
    "\n",
    "    S_mean_treatment = np.mean(treatment_converted)\n",
    "    N_mean_treatment = np.mean(treatment_samples_per_cluster)\n",
    "\n",
    "    sigma_S_control = np.var(control_converted)\n",
    "    sigma_N_control = np.var(control_samples_per_cluster)\n",
    "\n",
    "    sigma_S_treatment = np.var(treatment_converted)\n",
    "    sigma_N_treatment = np.var(treatment_samples_per_cluster)\n",
    "\n",
    "    sigma_S_N_control = np.cov(\n",
    "        control_converted, control_samples_per_cluster)[0, 1]\n",
    "    sigma_S_N_treatment = np.cov(\n",
    "        treatment_converted, treatment_samples_per_cluster)[0, 1]\n",
    "\n",
    "    Y_mean_control = S_mean_control / N_mean_control\n",
    "    Y_mean_var_control = (1 / (N * N_mean_control * N_mean_control)) * (sigma_S_control - 2 * S_mean_control * sigma_S_N_control /\n",
    "                                                                        N_mean_control + S_mean_control * S_mean_control * sigma_N_control / (N_mean_control * N_mean_control))\n",
    "\n",
    "    Y_mean_treatment = S_mean_treatment / N_mean_treatment\n",
    "    Y_mean_var_treatment = (1 / (N * N_mean_treatment * N_mean_treatment)) * (sigma_S_treatment - 2 * S_mean_treatment * sigma_S_N_treatment /\n",
    "                                                                        N_mean_treatment + S_mean_treatment * S_mean_treatment * sigma_N_treatment / (N_mean_treatment * N_mean_treatment))\n",
    "    \n",
    "    z_score = (Y_mean_treatment - Y_mean_control) / np.sqrt(Y_mean_var_control + Y_mean_var_treatment)\n",
    "    \n",
    "    if (z_score >= 1.96) or (z_score <= -1.96):\n",
    "        false_positive += 1\n",
    "\n",
    "print(\"Type One Error : {}\".format(false_positive / n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After doing the power analysis, calculate the sample size requirement, and assume this is no clusters exist in the samples, we noticed the simulation returns power 80% as we expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:46:56.594276Z",
     "start_time": "2019-10-08T18:46:56.590648Z"
    }
   },
   "outputs": [],
   "source": [
    "# 25% mean\n",
    "alpha_control = 1\n",
    "beta_control = 3\n",
    "\n",
    "# 26% mean\n",
    "# 1% absolute increase over control\n",
    "alpha_treatment = 1\n",
    "beta_treatment = 2.84615384615\n",
    "\n",
    "# need ~30000 samples in each cohort to achieve 80% power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:46:17.162842Z",
     "start_time": "2019-10-08T20:42:28.552177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power is : 0.8103\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metric in sample level\n",
    "N = 30000\n",
    "true_positive = 0\n",
    "for i in range(n_iterations):\n",
    "#     # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha_control, beta_control, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha_treatment, beta_treatment, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "#     control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "#     treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    control_samples_per_cluster = np.ones(shape=N, dtype=np.int64)\n",
    "    treatment_samples_per_cluster = np.ones(shape=N, dtype=np.int64)\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    # conversion in each cohort\n",
    "    control_cluster_conversion = sum(\n",
    "        control_converted) / sum(control_samples_per_cluster)\n",
    "    treatment_cluster_conversion = sum(\n",
    "        treatment_converted) / sum(treatment_samples_per_cluster)\n",
    "\n",
    "#     control_mean_list.append(control_cluster_conversion)\n",
    "#     treatment_mean_list.append(treatment_cluster_conversion)\n",
    "    \n",
    "    \n",
    "    # perform two proportion z-test\n",
    "    control_mean, var_c = control_cluster_conversion,  control_cluster_conversion * \\\n",
    "        (1 - control_cluster_conversion)\n",
    "    treatment_mean, var_t = treatment_cluster_conversion, treatment_cluster_conversion * \\\n",
    "        (1 - treatment_cluster_conversion)\n",
    "    z_score = (treatment_mean - control_mean) / np.sqrt(var_c /\n",
    "                                                        sum(control_samples_per_cluster) + var_t / sum(treatment_samples_per_cluster))\n",
    "\n",
    "    if (z_score >= 1.96) or (z_score <= -1.96):\n",
    "        true_positive += 1\n",
    "\n",
    "print(\"Power is : {}\".format(true_positive / n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After doing the power analysis, calculate the sample size requirement, and assume clusters exist in the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:58:56.491135Z",
     "start_time": "2019-10-08T18:58:56.488074Z"
    }
   },
   "outputs": [],
   "source": [
    "# 25% mean\n",
    "alpha_control = 1\n",
    "beta_control = 3\n",
    "\n",
    "# 26% mean\n",
    "# 1% absolute increase over control\n",
    "alpha_treatment = 1\n",
    "beta_treatment = 2.84615384615\n",
    "\n",
    "# need ~30000 samples in each cohort to achieve 80% power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:56:19.146505Z",
     "start_time": "2019-10-08T20:55:32.978058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power is : 0.7174\n"
     ]
    }
   ],
   "source": [
    "# Assume there are 5000 clusters and each cluster on average has 6 samples\n",
    "# Then ~30000 samples in each cohort\n",
    "N = 5000\n",
    "true_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha_control, beta_control, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha_treatment, beta_treatment, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # control_samples_per_cluster = np.ones(shape=N, dtype=np.int64)\n",
    "    # treatment_samples_per_cluster = np.ones(shape=N, dtype=np.int64)\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    # conversion in each cohort\n",
    "    control_cluster_conversion = sum(\n",
    "        control_converted) / sum(control_samples_per_cluster)\n",
    "    treatment_cluster_conversion = sum(\n",
    "        treatment_converted) / sum(treatment_samples_per_cluster)\n",
    "\n",
    "    \n",
    "    # perform two proportion z-test\n",
    "    control_mean, var_c = control_cluster_conversion,  control_cluster_conversion * \\\n",
    "        (1 - control_cluster_conversion)\n",
    "    treatment_mean, var_t = treatment_cluster_conversion, treatment_cluster_conversion * \\\n",
    "        (1 - treatment_cluster_conversion)\n",
    "    \n",
    "    z_score = (treatment_mean - control_mean) / np.sqrt(var_c /\n",
    "                                                        sum(control_samples_per_cluster) + var_t / sum(treatment_samples_per_cluster))\n",
    "    \n",
    "    if (z_score >= 1.96) or (z_score <= -1.96):\n",
    "        true_positive += 1\n",
    "\n",
    "print(\"Power is : {}\".format(true_positive / n_iterations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate each cluster samples into one point, and calculate the power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T18:39:05.116387Z",
     "start_time": "2019-10-09T18:39:05.113385Z"
    }
   },
   "outputs": [],
   "source": [
    "# 25% mean\n",
    "alpha_control = 1\n",
    "beta_control = 3\n",
    "\n",
    "# 26% mean\n",
    "# 1% absolute increase over control\n",
    "alpha_treatment = 1\n",
    "beta_treatment = 2.84615384615\n",
    "\n",
    "# The power must be less than 80% since we aggregate each clusters into one data point, sample size is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T18:39:29.702576Z",
     "start_time": "2019-10-09T18:39:06.152164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power is : 0.4696\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metric in cluster level\n",
    "# 5% significance level\n",
    "true_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha, beta, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha_treatment, beta_treatment, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    # conversion in each cluster\n",
    "    control_cluster_conversion = control_converted / control_samples_per_cluster\n",
    "    treatment_cluster_conversion = treatment_converted / treatment_samples_per_cluster\n",
    "\n",
    "    # perform t-test\n",
    "    control_mean, var_c = np.mean(control_cluster_conversion),  np.var(\n",
    "        control_cluster_conversion, ddof=1)\n",
    "    treatment_mean, var_t = np.mean(treatment_cluster_conversion), np.var(\n",
    "        treatment_cluster_conversion, ddof=1)\n",
    "    t_score = (treatment_mean - control_mean) / np.sqrt(var_c / N + var_t / N)\n",
    "\n",
    "    if (t_score >= 1.96) or (t_score <= -1.96):\n",
    "        true_positive += 1\n",
    "\n",
    "print(\"Power is : {}\".format(true_positive / n_iterations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the delta method to do the power  - the power doesn't change.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T18:39:36.095010Z",
     "start_time": "2019-10-09T18:39:36.091890Z"
    }
   },
   "outputs": [],
   "source": [
    "# 25% mean\n",
    "alpha_control = 1\n",
    "beta_control = 3\n",
    "\n",
    "# 26% mean\n",
    "# 1% absolute increase over control\n",
    "alpha_treatment = 1\n",
    "beta_treatment = 2.84615384615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T18:40:05.491948Z",
     "start_time": "2019-10-09T18:39:37.126859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power is : 0.4713\n"
     ]
    }
   ],
   "source": [
    "N = 5000\n",
    "true_positive = 0\n",
    "for i in range(n_iterations):\n",
    "    # conversion rate p in each cluster are from the same beta distribution in control and test group\n",
    "    control_cluster_p = np.random.beta(alpha_control, beta_control, N)\n",
    "    treatment_cluster_p = np.random.beta(alpha_treatment, beta_treatment, N)\n",
    "\n",
    "    # number of samples in each cluster, plus one to make sure the samples are greater than 1\n",
    "    control_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "    treatment_samples_per_cluster = np.random.poisson(mean_samples, N) + 1\n",
    "\n",
    "    # number of converted samples in each cluster\n",
    "    control_converted = np.random.binomial(\n",
    "        n=control_samples_per_cluster, p=control_cluster_p)\n",
    "\n",
    "    treatment_converted = np.random.binomial(\n",
    "        n=treatment_samples_per_cluster, p=treatment_cluster_p)\n",
    "\n",
    "    S_mean_control = np.mean(control_converted)\n",
    "    N_mean_control = np.mean(control_samples_per_cluster)\n",
    "\n",
    "    S_mean_treatment = np.mean(treatment_converted)\n",
    "    N_mean_treatment = np.mean(treatment_samples_per_cluster)\n",
    "\n",
    "    sigma_S_control = np.var(control_converted)\n",
    "    sigma_N_control = np.var(control_samples_per_cluster)\n",
    "\n",
    "    sigma_S_treatment = np.var(treatment_converted)\n",
    "    sigma_N_treatment = np.var(treatment_samples_per_cluster)\n",
    "\n",
    "    sigma_S_N_control = np.cov(\n",
    "        control_converted, control_samples_per_cluster)[0, 1]\n",
    "    sigma_S_N_treatment = np.cov(\n",
    "        treatment_converted, treatment_samples_per_cluster)[0, 1]\n",
    "\n",
    "    Y_mean_control = S_mean_control / N_mean_control\n",
    "    Y_mean_var_control = (1 / (N * N_mean_control * N_mean_control)) * (sigma_S_control - 2 * S_mean_control * sigma_S_N_control /\n",
    "                                                                        N_mean_control + S_mean_control * S_mean_control * sigma_N_control / (N_mean_control * N_mean_control))\n",
    "\n",
    "    Y_mean_treatment = S_mean_treatment / N_mean_treatment\n",
    "    Y_mean_var_treatment = (1 / (N * N_mean_treatment * N_mean_treatment)) * (sigma_S_treatment - 2 * S_mean_treatment * sigma_S_N_treatment /\n",
    "                                                                        N_mean_treatment + S_mean_treatment * S_mean_treatment * sigma_N_treatment / (N_mean_treatment * N_mean_treatment))\n",
    "    \n",
    "    z_score = (Y_mean_treatment - Y_mean_control) / np.sqrt(Y_mean_var_control + Y_mean_var_treatment)\n",
    "    \n",
    "    if (z_score >= 1.96) or (z_score <= -1.96):\n",
    "        true_positive += 1\n",
    "\n",
    "print(\"Power is : {}\".format(true_positive / n_iterations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
